# Importing libraries
import tweepy
import matplotlib.pyplot as plt
import numpy as np
import nltk
from textblob import TextBlob
from statistics import stdev
from statistics import median
from statistics import variance
from collections import Counter
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Keys from Twitter Dev Console
consumer_key = "xxxx"
consumer_secret = "xxxxx"
access_token = "xxxxx"
access_token_secret = "xxxxx"
# Initializing variables
totalLen = 0
totalTweets = 0
tweetArray = []
totalWords = 0
wordArray = []
positiveSentimentArray = []
neutralSentimentArray = []
negativeSentimentArray = []
query = ""
language = ""
totalTweetText = ""
vader = SentimentIntensityAnalyzer
# Attempts to verify API keys, prints failure if not verified
try:
    # Creating authentication object
    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
    # Setting access token and secret
    auth.set_access_token(access_token, access_token_secret)
    # Creating the API object while passing in auth information
    api = tweepy.API(auth)

except:
    print("Authentication Failed")

    # Allows user to narrow their search for a certain query and language
def inputSearchLanguage():
    global query
    global language
    # Using a Query to search for tweets with a certain hashtag
    query = input("What hashtag would you like to search for? ")
    # Specifying a language
    language = input("What language would you like to search for? ")
    # Searches for the specified query in the specified language

def searchTweets():
    # Creating global variables
    global totalLen
    global totalTweets
    global tweetArray
    global totalWords
    global wordArray
    global positiveSentimentArray
    global neutralSentimentArray
    global negativeSentimentArray
    global totalTweetText
    # Calling search + language function for the api to narrow the search
    results = api.search(q=query, lang=language, place_country="US")
    for tweet in results:
        # Prints Twitter username, their tweet, and their location(if available)
        print(tweet.user.screen_name, "Tweeted: ", tweet.text, tweet.user.location)
        # Converts twitter characters into a number
        totalLen = totalLen + len(tweet.text)
        # Counts the number of total tweets
        totalTweets = totalTweets + 1
        tweetArray.append(len(tweet.text))
        totalWords = totalWords + len(tweet.text.split(" "))
        wordArray.append(len(tweet.text.split(" ")))
        totalTweetText = totalTweetText + tweet.text
        analysis = TextBlob(tweet.text)
        analysis.correct()
        if analysis.sentiment.polarity > 0:
            positiveSentimentArray.append(tweet.text)
        elif analysis.sentiment.polarity == 0:
            neutralSentimentArray.append(tweet.text)
        else:
            negativeSentimentArray.append(tweet.text)

def printStats():
    # Prints a list of statistics(mean, median, variance) for both characters and words
    print("Average Character Length of Collected Tweets: ", float(totalLen/totalTweets), "Total Tweets Collected: ", totalTweets, "Standard Deviation of Characters in Collected Tweets: ", stdev(tweetArray,float(totalLen/totalTweets)),"Median of Characters in Collected Tweets: ", median(tweetArray), "Variance of Characters in Collected Tweets: ", variance(tweetArray, float(totalLen/totalTweets)), "Average Word Count of Collected Tweets: ", totalWords/totalTweets, "Standard Deviation of Words in Collected Tweets: ", stdev(wordArray,float(totalWords/totalTweets)), "Variance of Words in Collected Tweets: ", variance(wordArray, float(totalWords/totalTweets)), "Median of Words in Collected Tweets: ", median(wordArray))
    print("Positive Tweets: " + str(positiveSentimentArray) + "Neutral Tweets:" + str(neutralSentimentArray) + "Negative Tweets: " + str(negativeSentimentArray))
    printGraphs()
# Prints graphs for characters + words
def printGraphs():
    # Counts the most common words
    wordCount = Counter(totalTweetText.split(" "))
    # Bins for graphs
    characterBins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240]
    wordBins = [0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48]
    # Prints a histogram for characters of collected tweets
    plt.hist(tweetArray, bins = characterBins, histtype = 'bar', color='#0504aa', alpha = .7, rwidth = .8)
    plt.grid(axis='y', alpha=0.75)
    plt.xlabel("Number of Characters")
    plt.ylabel("Frequency")
    plt.title("Histogram of Character Frequency")
    plt.text(0, 0, r'$\bar{x}=' + str(round(float(totalLen/totalTweets), 2)) + ', Sx= $ ' + str(round(stdev(tweetArray,float(totalLen/totalTweets)), 2)))
    plt.show()

    # Prints a histogram for words of collected tweets
    plt.hist(wordArray, bins = wordBins, histtype = 'bar', color='#0504aa', alpha = .7, rwidth = .8)
    plt.grid(axis='y', alpha=0.75)
    plt.xlabel("Number of Words")
    plt.ylabel("Frequency")
    plt.title("Histogram of Word Frequency")
    plt.text(0, 0, r'$\bar{x}=' + str(round(float(totalWords/totalTweets), 2)) + ', Sx= $ ' + str(round(stdev(wordArray,float(totalWords/totalTweets)), 2)))
    plt.show()

    # Creates a bar graph of most common words
    info = wordCount.most_common(5)
    names, values = zip(*info)
    ind = np.arange(len(info))
    width = 0.35
    fig, ax = plt.subplots()
    rects1 = ax.bar(ind, values, width, color='r')
    ax.set_ylabel('Frequency')
    ax.set_xlabel('Words')
    ax.set_title('Bar Graph of Most Frequent Words')
    ax.set_xticks(ind+width/2.)
    ax.set_xticklabels(names)
    def autolabel(rects):
        for rect in rects:
            height = rect.get_height()
            ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,
                '%d' % int(height),
                ha='center', va='bottom')

    autolabel(rects1)
    plt.show()

    # Creates filtered bar graph for most common words
    removeList = ["a","an","the","but","by","be","to","of","in","that","have","I","it","for","as","not","this", "and", "on", "is", "The", "would", "are", "were", "u","having", "has", "at", "been", "when", "which", "who", "their", "so", "up", "or", "yet", "=", "with","could","because","into","my", "you", "If", "This", "It", "Since", "all", "All", "since"]
    for word in removeList:
        if word in wordCount:
            del wordCount[word]
    info = wordCount.most_common(7)
    names, values = zip(*info)
    ind = np.arange(len(info))
    width = 0.35
    fig, ax = plt.subplots()
    rects1 = ax.bar(ind, values, width, color='r')
    ax.set_ylabel('Frequency')
    ax.set_xlabel('Words')
    ax.set_title('Bar Graph of Most Frequent Words(Filtered)')
    ax.set_xticks(ind+width/2.)
    ax.set_xticklabels(names)
    autolabel(rects1)
    plt.show()

inputSearchLanguage()
searchTweets()
printStats()
