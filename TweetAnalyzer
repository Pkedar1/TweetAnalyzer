# Importing libraries
import tweepy
import matplotlib.pyplot as plt
import numpy as np
import xlrd
import xlsxwriter
import pathlib
import openpyxl
from openpyxl import Workbook
from openpyxl import load_workbook
from statistics import stdev
from statistics import median
from statistics import variance
from collections import Counter
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Keys from Twitter Dev Console
consumer_key = "xxxxxx"
consumer_secret = "xxxxx"
access_token = "xxxxxx"
access_token_secret = "xxxxxxx"
# Initializing variables
totalLen = 0
totalTweets = 0
tweetArray = []
totalWords = 0
wordArray = []
positiveTotalText = ""
negativeTotalText = ""
positiveSentimentArray = []
neutralSentimentArray = []
negativeSentimentArray = []
query = ""
language = ""
totalTweetText = ""
row = 0

# Attempts to verify API keys, prints failure if not verified
try:
    # Creating authentication object
    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
    # Setting access token and secret
    auth.set_access_token(access_token, access_token_secret)
    # Creating the API object while passing in auth information
    api = tweepy.API(auth)

except:
    print("Authentication Failed")

    # Allows user to narrow their search for a certain query and language
def inputSearchLanguage():
    global query
    global language
    # Using a query to search for tweets with a certain hashtag
    query = "COVID-19" + "-filter:retweets"
    # Specifying a language
    language = "en"


def pullTweets():
    global row
    file = pathlib.Path("tweets.xlsx")
    if file.exists():
        book = load_workbook(filename='tweets.xlsx')
    else:
         book = Workbook()

    nworksheet = book.active
    # Calling search + language function for the api to narrow the search
    results = api.search(q=query, lang=language, place_country="US")
    for tweet in results:
        # Prints Twitter username, their tweet, and their location(if available)
        print(tweet.user.screen_name, "Tweeted: ", tweet.text, tweet.user.location)
        nworksheet.append([tweet.text])
        row += 1
    book.save('tweets.xlsx')


def calculateValues():
    # Creating global variables
    global totalLen
    global totalTweets
    global tweetArray
    global totalWords
    global wordArray
    global positiveSentimentArray
    global neutralSentimentArray
    global negativeSentimentArray
    global totalTweetText
    global positiveTotalText
    global negativeTotalText
    global row
    vader = SentimentIntensityAnalyzer()
    workbook = xlrd.open_workbook("tweets.xlsx")
    sheet = workbook.sheet_by_index(0)
    for rowx in range(sheet.nrows):
        line = sheet.row_values(rowx)
        tweet = line[0]
        print(tweet)

        # Converts twitter characters into a number
        totalLen = totalLen + len(tweet)
        # Counts the number of total tweet
        totalTweets = totalTweets + 1
        tweetArray.append(len(tweet))
        totalWords = totalWords + len(tweet.split(" "))
        wordArray.append(len(tweet.split(" ")))
        totalTweetText = totalTweetText + tweet
        sentimentAnalysis = vader.polarity_scores(tweet)

        if sentimentAnalysis['compound'] > .05:
            positiveSentimentArray.append(tweet)
            positiveTotalText = positiveTotalText + tweet
        elif sentimentAnalysis['compound'] < -.05:
            negativeSentimentArray.append(tweet)
            negativeTotalText = negativeTotalText + tweet
        else:
            neutralSentimentArray.append(tweet)


def printStats():
    # Prints a list of statistics(mean, median, variance) for both characters and words
    print("Average Character Length of Collected Tweets: ", float(totalLen/totalTweets), "Total Tweets Collected: ", totalTweets, "Standard Deviation of Characters in Collected Tweets: ", stdev(tweetArray,float(totalLen/totalTweets)),"Median of Characters in Collected Tweets: ", median(tweetArray), "Variance of Characters in Collected Tweets: ", variance(tweetArray, float(totalLen/totalTweets)), "Average Word Count of Collected Tweets: ", totalWords/totalTweets, "Standard Deviation of Words in Collected Tweets: ", stdev(wordArray,float(totalWords/totalTweets)), "Variance of Words in Collected Tweets: ", variance(wordArray, float(totalWords/totalTweets)), "Median of Words in Collected Tweets: ", median(wordArray))
    print("Positive Tweets: " + str(positiveSentimentArray) + "Neutral/Undecided Tweets:" + str(neutralSentimentArray) + "Negative Tweets: " + str(negativeSentimentArray))
    printGraphs()
# Prints graphs for characters + words


def printGraphs():
    # Counts the most common words
    wordCount = Counter(totalTweetText.split(" "))
    positiveWordCount = Counter(positiveTotalText.split(" "))
    negativeWordCount = Counter(negativeTotalText.split(" "))
    # Bins for graphs
    characterBins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240]
    wordBins = [0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48]
    # Prints a histogram for characters of collected tweets
    plt.hist(tweetArray, bins = characterBins, histtype = 'bar', color='#0504aa', alpha = .7, rwidth = .8)
    plt.grid(axis='y', alpha=0.75)
    plt.xlabel("Number of Characters")
    plt.ylabel("Frequency")
    plt.title("Histogram of Character Frequency")
    plt.text(0, 0, r'$\bar{x}=' + str(round(float(totalLen/totalTweets), 2)) + ', Sx= $ ' + str(round(stdev(tweetArray,float(totalLen/totalTweets)), 2)))
    plt.show()

    # Prints a histogram for words of collected tweets
    plt.hist(wordArray, bins = wordBins, histtype = 'bar', color='#0504aa', alpha = .7, rwidth = .8)
    plt.grid(axis='y', alpha=0.75)
    plt.xlabel("Number of Words")
    plt.ylabel("Frequency")
    plt.title("Histogram of Word Frequency")
    plt.text(0, 0, r'$\bar{x}=' + str(round(float(totalWords/totalTweets), 2)) + ', Sx= $ ' + str(round(stdev(wordArray,float(totalWords/totalTweets)), 2)))
    plt.show()
    wordGraphs(wordCount, "")
    if positiveSentimentArray == []:
        print("No positive tweets found")
    else:wordGraphs(positiveWordCount, "Positive")
    if negativeSentimentArray == []:
        print("No negative tweets found")
    else: wordGraphs(negativeWordCount, "Negative")


def wordGraphs(wordCount, sentiment):
    # Creates a bar graph of most common words
    info = wordCount.most_common(5)
    names, values = zip(*info)
    ind = np.arange(len(info))
    width = 0.35
    fig, ax = plt.subplots()
    rects1 = ax.bar(ind, values, width, color='r')
    ax.set_ylabel('Frequency')
    ax.set_xlabel('Words')
    ax.set_title('Bar Graph of Most Frequent ' + sentiment + ' Words')
    ax.set_xticks(ind+width/2.)
    ax.set_xticklabels(names)
    def autolabel(rects):
        for rect in rects:
            height = rect.get_height()
            ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,
                    '%d' % int(height),
                    ha='center', va='bottom')

    autolabel(rects1)
    plt.show()

    # Creates filtered bar graph for most common words
    removeList = ["a","an","the","but","by","be","to","of","in","that","have","I","it","for","as","not","this", "and", "on", "is", "The", "would", "are", "were", "u","having", "has", "at", "been", "when", "which", "who", "their", "so", "up", "or", "yet", "=", "with","could","because","into","my", "you", "If", "This", "It", "Since", "all", "All", "since", "was", "Was", "your", "-", "his", "&amp;", "#COVID", "#covid","#COVID-19","#covid-19", "will", "can", " ", "they", "if", "He", "She", "she", "  ", "   ", "from", "us", "we", "A", "our", "You", "Your","how","about", "In", "How", "About", "do","Are"]
    for word in removeList:
        if word in wordCount:
            del wordCount[word]
    info = wordCount.most_common(5)
    names, values = zip(*info)
    ind = np.arange(len(info))
    width = 0.35
    fig, ax = plt.subplots()
    rects1 = ax.bar(ind, values, width, color='r')
    ax.set_ylabel('Frequency')
    ax.set_xlabel('Words')
    ax.set_title('Bar Graph of Most Frequent ' + sentiment + ' Words(Filtered)')
    ax.set_xticks(ind+width/2.)
    ax.set_xticklabels(names)
    autolabel(rects1)
    plt.show()

inputSearchLanguage()
pullTweets()
calculateValues()
printStats()
